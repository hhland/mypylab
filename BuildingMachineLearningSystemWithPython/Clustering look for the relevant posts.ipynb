{
 "metadata": {
  "name": "",
  "signature": "sha256:45f389487b5168162a6415df7e914e45de8a2d2dc88a36949aa9e939ceab8881"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import os\n",
      "import sys\n",
      "from sklearn.feature_extraction.text import CountVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['f']\n",
        "`%matplotlib` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\u53c2\u6570min_df\u51b3\u5b9a\u4e86CountVectorizer\u5982\u4f55\u5904\u7406\u90a3\u4e9b\u4e0d\u7ecf\u5e38\u4f7f\u7528\u7684\u8bcd\u8bed\uff08\u6700\u5c0f\u6587\u6863\u9891\u7387\uff09\u3002\u5982\u679c\u5c06\u5b83\u8bbe\u6210\u4e00\u4e2a\u6574\u6570\uff0c\u90a3\u4e48\u6240\u6709\u51fa\u73b0\u6b21\u6570\u5c0f\u4e8e\u8fd9\u4e2a\u503c\u7684\u8bcd\u8bed\u90fd\u5c06\u88ab\u6254\u6389\u3002\u5982\u679c\u5b83\u662f\u4e00\u4e2a\u6bd4\u4f8b\uff0c\u90a3\u4e48\u6240\u6709\u5728\u6574\u4e2a\u6570\u636e\u96c6\u4e2d\u51fa\u73b0\u6bd4\u4f8b\u5c0f\u4e8e\u8fd9\u4e2a\u503c\u7684\u8bcd\u8bed\u90fd\u5c06\u88ab\u6254\u6389\u3002"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hr=\"-\"*120\n",
      "vectorizer = CountVectorizer(min_df=1)\n",
      "vectorizer\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "CountVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
        "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "content = [\"How to format my hard disk\", \" Hard disk format problems \"]\n",
      "x = vectorizer.fit_transform(content)\n",
      "vectorizer.get_feature_names(),hr,x.toarray().transpose()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "([u'disk', u'format', u'hard', u'how', u'my', u'problems', u'to'],\n",
        " '------------------------------------------------------------------------------------------------------------------------',\n",
        " array([[1, 1],\n",
        "        [1, 1],\n",
        "        [1, 1],\n",
        "        [1, 0],\n",
        "        [1, 0],\n",
        "        [0, 1],\n",
        "        [1, 0]]))"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file tmp/01.txt\n",
      "This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing tmp/01.txt\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file tmp/02.txt\n",
      "Imaging databases can get huge."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing tmp/02.txt\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file tmp/03.txt\t\n",
      "Most imaging databases safe images permanently."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing tmp/03.txt\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file tmp/04.txt\t\n",
      "Imaging databases store images."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing tmp/04.txt\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file tmp/05.txt\n",
      "Imaging databases store images. Imaging databases store images. Imaging databases store images."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing tmp/05.txt\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmpdir=\"tmp\"\n",
      "posts = [open(os.path.join(tmpdir,\"0\"+str(f)+\".txt\")).read() for f in range(1,5) ]\n",
      "posts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "['This is a toy post about machine learning. Actually, it contains not much interesting stuff.',\n",
        " 'Imaging databases can get huge.',\n",
        " 'Most imaging databases safe images permanently.',\n",
        " 'Imaging databases store images.']"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = vectorizer.fit_transform(posts)\n",
      "num_samples, num_features = X_train.shape\n",
      "\"#samples: %d, #features: %d\" % (num_samples,num_features),hr,vectorizer.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "('#samples: 4, #features: 24',\n",
        " '------------------------------------------------------------------------------------------------------------------------',\n",
        " [u'about',\n",
        "  u'actually',\n",
        "  u'can',\n",
        "  u'contains',\n",
        "  u'databases',\n",
        "  u'get',\n",
        "  u'huge',\n",
        "  u'images',\n",
        "  u'imaging',\n",
        "  u'interesting',\n",
        "  u'is',\n",
        "  u'it',\n",
        "  u'learning',\n",
        "  u'machine',\n",
        "  u'most',\n",
        "  u'much',\n",
        "  u'not',\n",
        "  u'permanently',\n",
        "  u'post',\n",
        "  u'safe',\n",
        "  u'store',\n",
        "  u'stuff',\n",
        "  u'this',\n",
        "  u'toy'])"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_post = \"imaging databases\"\n",
      "new_post_vec = vectorizer.transform([new_post])\n",
      "new_post_vec.toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "array([[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0]])"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dist_raw(v1, v2):\n",
      "    delta = v1-v2\n",
      "    return sp.linalg.norm(delta.toarray())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best_doc = None\n",
      "best_dist = sys.maxint\n",
      "best_i = None\n",
      "for i in range(0, num_samples):\n",
      "    post = posts[i]\n",
      "    if post==new_post:\n",
      "        continue\n",
      "    post_vec = X_train.getrow(i)\n",
      "    d = dist(post_vec, new_post_vec)\n",
      "\n",
      "\"=== Post %i with dist=%.2f: %s\"%(i, d, post)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Cannot find a common data type.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-34-8cdacc8e05c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mpost_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_post_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;34m\"=== Post %i with dist=%.2f: %s\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/pymodules/python2.7/matplotlib/mlab.pyc\u001b[0m in \u001b[0;36mdist\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \"\"\"\n\u001b[0;32m   1103\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdist_point_to_segment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: Cannot find a common data type."
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}